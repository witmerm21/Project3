Instructions for creating a dataset to run via Picotte. Each Python script will require directories to be changed, they are located at the top of each script.

(This assumes that you already have a folder, containing a folder for each sequence as a .FNA file)

1 - Run make_ncbi_csv.py, this script will read through the folder containing all the sequences and look up the folder name (sequence number) in the NCBI database. It will then save the taxonomic results to a CSV that relates each folder/sequence number, file name, NCBI refrence number, and the organism's taxonomic data (sequences.csv).

2 - Run make_taxonomic_level_csv.py, this script will go through sequences.csv (output CSV from step 1) and calculate the abundance of organisms in each taxonomic group for each taxonomic level (unique_levels.csv). For this project, our group decided to train on the top five most abundant groups for each taxonomic level. A new CSV was created from unique_levels.csv that included only these top five most abundant group (unique_levels_min70.csv). This is not required for any scripts, but was done for clarification and readability.

3 - The most tedious part. It was decided that the quickest way to pick the organisms for each trial was to manually copy/paste the sequence numbers from the Excel sheet into a TXT file for each trial, rather than write code to automate it. These TXT files are included in datatxt.zip for refrence. For a given taxonomic group that would be trained on, the Excel sheet was sorted to only show organisms within that group. Then, the sequence number column was copied and pasted into a new TXT file representing the training set. For the far test set, the Excel sheet was sorted to show all the organisms belonging to the taxonomic group one level higher that the current one, then the largest non-training group was sorted and filtered for. Repeat the same process of making a TXT file for this new set of organisms.

4 - Run make_test_row_index.py, this script goes through the single testing sequence file (seq.fna) and locates the start of each organism's reads. The start of each organism is denoted by a line that consists of just their sequence number. Each sequence number and its row number are then saved to testnumberrows.csv for the next step.

5 - Run generate_trials.py, this is the final script for creating the dataset. This script makes use of testnumberrows.csv, the TXT files created in step 3, the sequences folder, and the testing sequence file (seq.fna). It first creates the folder structure for all the trials (20%, 40%, 50%, far, near). Then, using the TXT files of all the organisms for each trial, it makes lists for each permutation of the trial. These lists are then used to either copy files from the sequences folder for the training and near testing sets, or copy lines from seq.fna for the far testing sets. After running, a main folder will be created that contains the folder for each unique trial, and within each folder is each permutation for 20%, 40%, and 50%, then within each of those folders is a training set, near test set, and far test set. The training set is a folder of folders for each sequence file. The two test sets are each a single file (seq.fna) that contains the lines for their given testing sequences.

Once these steps are completed, the dataset has been fully made and is ready to be run through Jelly and NBC.
